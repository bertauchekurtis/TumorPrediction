load("C:/Users/kurti/Desktop/PhosphoPep/data/sample/slr_r_p.RData")
shiny::runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
xgb_results <- read.csv("data/sample/XG Boost Results.csv")
xgb_results <- read.csv("C:/Users/kurti/Desktop/PhosphoPep/data/sample/XG Boost Results.csv")
rbPal <- colorRampPalette(c("#117833", "#d422bf"))
xgb_results$res <- sampleData$RetentionTime - xgb_results$Prediction
sampleData <- read.csv("C:/Users/kurti/Desktop/PhosphoPep/data/testingSet_withVars_DATA_ONE.csv")
xgb_results$res <- sampleData$RetentionTime - xgb_results$Prediction
xgb_results$mod_res <- (abs(xgb_results$res)) ^ (1/3)
xgb_results$col <- rbPal(200)[as.numeric(cut(xgb_results$mod_res,breaks = 200))]
plot(x = sampleData$RetentionTime, y = xgb_results$Prediction, col = xgb_results$col)
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?renderPlot
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
View(xgb_results)
View(xgb_results)
View(xgb_results)
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?plot
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?barplot
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?abline
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?lines
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
shiny::runApp('C:/Users/kurti/Desktop/PhosphoPep')
?bsToolTip
?bsTooltip
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
shiny::runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
sampleData <- read.csv("C:/Users/kurti/Desktop/PhosphoPep/data/testingSet_withVars_DATA_ONE.csv")
slr <- read.csv("C:/Users/kurti/Downloads/full/Linear Regression.csv")
slr <- read.csv("C:/Users/kurti/Downloads/full/Linear Regression.csv")
step <- read.csv("C:/Users/kurti/Downloads/full/Best Subset Regression.csv")
ridge <- read.csv("C:/Users/kurti/Downloads/full/Ridge Regression.csv")
lasso <- read.csv("C:/Users/kurti/Downloads/full/Lasso Regression.csv")
elastic <- read.csv("C:/Users/kurti/Downloads/full/Elastic Net Regression.csv")
rf <- read.csv("C:/Users/kurti/Downloads/full/Random Forest.csv")
xgb <- read.csv("C:/Users/kurti/Downloads/full/XG Boost (1).csv")
svr <- read.csv("C:/Users/kurti/Downloads/full/Support Vector Regression.csv")
calcWinStats = function(trueResponse, predictedResponse)
{
# window
q <- quantile(residuals, probs =c(.025,.975))
window <- abs(q[1]) + abs(q[2])
c(window, q[1], q[2], mean(residuals))
}
calcWinStats = function(trueResponse, predictedResponse)
{
# window
q <- quantile(residuals, probs =c(.025,.975))
window <- abs(q[1]) + abs(q[2])
c(window, q[1], q[2], mean(residuals))
}
slr_w <- calcStats(phosphoData$RetentionTime, slr$Prediction)
slr_w <- calcWinStats(phosphoData$RetentionTime, slr$Prediction)
calcWinStats = function(trueResponse, predictedResponse)
{
residuals <- trueResponse - predictedResponse
# window
q <- quantile(residuals, probs =c(.025,.975))
window <- abs(q[1]) + abs(q[2])
c(window, q[1], q[2], mean(residuals))
}
slr_w <- calcWinStats(phosphoData$RetentionTime, slr$Prediction)
slr_w <- calcWinStats(sampleData$RetentionTime, slr$Prediction)
step_w <- calcWinStats(sampleData$RetentionTime, step$Prediction)
lasso_w <- calcWinStats(sampleData$RetentionTime, lasso$Prediction)
ridge_w <- calcWinStats(sampleData$RetentionTime, ridge$Prediction)
elastic_w <- calcWinStats(sampleData$RetentionTime, elastic$Prediction)
rf_w <- calcWinStats(sampleData$RetentionTime, rf$prediction)
rf_w <- calcWinStats(sampleData$RetentionTime, rf$prediction)
xgb_w <- calcWinStats(sampleData$RetentionTime, xgb$Prediction)
svr_w <- calcWinStats(sampleData$RetentionTime, svr$Prediction)
rf_w <- calcWinStats(sampleData$RetentionTime, rf$Prediction)
save(slr_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/slr_w.RData")
save(step_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/step_w.RData")
save(lasso_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/lasso_w.RData")
save(ridge_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/ridge_w.RData")
save(slr_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/slr_w.RData")
save(step_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/step_w.RData")
save(lasso_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/lasso_w.RData")
save(ridge_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/ridge_w.RData")
save(elastic_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/elastic_w.RData")
save(rf_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/rf_w.RData")
save(xgb_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/xgb_w.RData")
save(svr_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/svr_w.RData")
install.packages("plotrix")
?runif
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
slr_w <- load("C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/slr_w.RData")
slr_w <- calcWinStats(sampleData$RetentionTime, slr$Prediction)
save(slr_w, file = "C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/slr_w.RData")
load("C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/slr_w.RData")
runApp('C:/Users/kurti/Desktop/PhosphoPep')
load("C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/slr_w.RData")
load("C:/Users/kurti/Desktop/PhosphoPep/data/sample/window/step_w.RData")
windowResults <- rbind(slr_w, step_w)
windowResults <- rbind(windowResults, ridge_w)
windowResults <- rbind(windowResults, lasso_w)
windowResults <- rbind(windowResults, elastic_w)
windowResults <- rbind(windowResults, rf_w)
windowResults <- rbind(windowResults, xgb_w)
windowResults <- rbind(windowResults, svr_w)
View(windowResults)
colnames(windowResults) <- c("size", "low", "high", "mean")
windowResults$size
windowResults[,1]
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?plotCI
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
?abline
runApp('C:/Users/kurti/Desktop/PhosphoPep')
runApp('C:/Users/kurti/Desktop/PhosphoPep')
shiny::runApp('C:/Users/kurti/Desktop/PhosphoPep - Copy')
load("C:/Users/kurti/Desktop/PhosphoPep/data/sample/XG Boost Results.csv")
load("C:/Users/kurti/Desktop/PhosphoPep - Copy/data/sample/XG Boost Results.csv")
runApp('C:/Users/kurti/Desktop/PhosphoPep - Copy')
deltaFleet <- read.csv(file = "C:/Users/kurti/Desktop/delta.csv")
deltaFleet$X <- NULL
deltaFleet$total <- deltaFleet$Delta.One + deltaFleet$First.Class + deltaFleet$Premimum.Select + deltaFleet$Delta.Comfort. + deltaFleet$Main.Cabin
deltaFleet$PremiumCabins <- deltaFleet$Delta.One + deltaFleet$First.Class
deltaFleet$EconomyCabins <- deltaFleet$total - deltaFleet$PremiumCabins
smaller <- deltaFleet[,c(10,11)]
smaller$total <- smaller$PremiumCabins + smaller$EconomyCabins
smaller$PremiumCabins <- smaller$PremiumCabins / smaller$total
smaller$EconomyCabins <- smaller$EconomyCabins / smaller$total
smaller$total <- NULL
smaller <- t(smaller)
barplot(height = as.matrix(smaller),
xlab = "Plane",
names.arg = round(smaller[1,], 2),
col = c("Blue","green"))
library(glmnet)
library(ROCR)
library(glmnet)
test_data <- read.csv("data/clean/testing.csv")
setwd("C:/Users/kurti/Desktop/TumorPrediction")
test_data <- read.csv("data/clean/testing.csv")
load("models/lasso_model.RData")
load("results/lasso_confusion_matrix.RData")
test_data_glm_matrix <- model.matrix(Outcome ~ .,
test_data)[,-1]
lasso_confusion_matrix
lasso_predictions <- predict(lasso_model,
newx = test_data_glm_matrix,
type = "response")
hm <- calcMetrics(lasso_confusion_matrix,
lasso_predictions,
test_data$Outcome)
calcMetrics <- function(confusion_matrix, predictions, labels)
{
accuracy <- confusion_matrix$overall[1]
sensitivity <- confusion_matrix$byClass[1]
specificity <- confusion_matrix$byClass[2]
false_positive_rate <- (confusion_matrix$table[2]/(confusion_matrix$table[2] + confusion_matrix$table[1]))
false_negative_rate <- (confusion_matrix$table[3]/(confusion_matrix$table[4]+confusion_matrix$table[3]))
positive_predictive_value <- confusion_matrix$byClass[3]
negative_predictive_value <- confusion_matrix$byClass[4]
positive_likelihood_ratio <- sensitivity / false_positive_rate
negative_likelihood_ratio <- false_negative_rate / specificity
diagnostic_odds_ratio <- positive_likelihood_ratio / negative_likelihood_ratio
f1_score <- (1 + 1^2) * ((sensitivity*positive_predictive_value)/(((1^2)*positive_predictive_value)+sensitivity))
f2_score <- (1 + 2^2) * ((sensitivity*positive_predictive_value)/(((2^2)*positive_predictive_value)+sensitivity))
youden_index <- sensitivity + specificity - 1
pred <- prediction(predictions, labels)
auc_perf <- performance(pred, measure = "auc")
area_under_roc_curve <- auc_perf@y.values
returnFrame<- data.frame(accuracy = c(accuracy),
sensitivity = c(sensitivity),
specificity = c(specificity),
false_positive_rate = c(false_positive_rate),
false_negative_rate = c(false_negative_rate),
positive_predictive_value = c(positive_predictive_value),
negative_predictive_value = c(negative_predictive_value),
area_under_roc_curve = c(area_under_roc_curve),
positive_likelihood_ratio = c(positive_likelihood_ratio),
negative_likelihood_ratio = c(negative_likelihood_ratio),
diagnostic_odds_ratio = c(diagnostic_odds_ratio),
f1_score = c(f1_score),
f2_score = c(f2_score),
youden_index = c(youden_index))
return(returnFrame)
c(accuracy,
sensitivity,
specificity,
false_positive_rate,
false_negative_rate,
positive_predictive_value,
negative_predictive_value,
area_under_roc_curve,
positive_likelihood_ratio,
negative_likelihood_ratio,
diagnostic_odds_ratio,
f1_score,
f2_score,
youden_index)
}
load("models/lasso_model.RData")
load("results/lasso_confusion_matrix.RData")
test_data_glm_matrix <- model.matrix(Outcome ~ .,
test_data)[,-1]
lasso_predictions <- predict(lasso_model,
newx = test_data_glm_matrix,
type = "response")
hm <- calcMetrics(lasso_confusion_matrix,
lasso_predictions,
test_data$Outcome)
View(hm)
confusion_matrix <- lasso_confusion_matrix
confusion_matrix
accuracy <- confusion_matrix$overall[1]
sensitivity <- confusion_matrix$byClass[1]
library(Caret)
library(caret)
?confusionMatrix
# open data
train_data <- read.csv("data/clean/training.csv")
# libraries
library(glmnet)
library(caret)
set.seed(37)
# open data
train_data <- read.csv("data/clean/training.csv")
test_data <- read.csv("data/clean/testing.csv")
# glm models require matrices
train_data_glm_matrix <- model.matrix(Outcome~.,
train_data)[,-1]
test_data_glm_matrix <- model.matrix(Outcome ~ .,
test_data)[,-1]
train_data_labels <- train_data$Outcome
# set up cv
foldid <- sample(rep(seq(5), length.out = nrow(train_data)))
# fit penalized lasso model (cv)
fit_lasso_cv <- cv.glmnet(x = train_data_glm_matrix,
y = train_data_labels,
family = "binomial",
alpha = 1,
nfolds = 5,
foldid = foldid)
# select best model
lasso_model <- glmnet(x = train_data_glm_matrix,
y = train_data_labels,
family = "binomial",
alpha = 1,
lambda = fit_lasso_cv$lambda.min)
# evaluate lasso
lasso_predictions <- predict(lasso_model,
newx = test_data_glm_matrix,
type = "response")
lasso_predictions <- ifelse(lasso_predictions > 0.5,
1,
0)
lasso_confusion_matrix <- confusionMatrix(data = factor(lasso_predictions),
reference = factor(test_data$Outcome),
positive = "1")
# save
save(lasso_model, file = "models/lasso_model.RData")
save(lasso_confusion_matrix, file = "results/lasso_confusion_matrix.RData")
load("models/lasso_model.RData")
load("results/lasso_confusion_matrix.RData")
test_data_glm_matrix <- model.matrix(Outcome ~ .,
test_data)[,-1]
lasso_predictions <- predict(lasso_model,
newx = test_data_glm_matrix,
type = "response")
hm <- calcMetrics(lasso_confusion_matrix,
lasso_predictions,
test_data$Outcome)
calcMetrics <- function(confusion_matrix, predictions, labels)
{
accuracy <- confusion_matrix$overall[1]
sensitivity <- confusion_matrix$byClass[1]
specificity <- confusion_matrix$byClass[2]
false_positive_rate <- (confusion_matrix$table[2]/(confusion_matrix$table[2] + confusion_matrix$table[1]))
false_negative_rate <- (confusion_matrix$table[3]/(confusion_matrix$table[4]+confusion_matrix$table[3]))
positive_predictive_value <- confusion_matrix$byClass[3]
negative_predictive_value <- confusion_matrix$byClass[4]
positive_likelihood_ratio <- sensitivity / false_positive_rate
negative_likelihood_ratio <- false_negative_rate / specificity
diagnostic_odds_ratio <- positive_likelihood_ratio / negative_likelihood_ratio
f1_score <- (1 + 1^2) * ((sensitivity*positive_predictive_value)/(((1^2)*positive_predictive_value)+sensitivity))
f2_score <- (1 + 2^2) * ((sensitivity*positive_predictive_value)/(((2^2)*positive_predictive_value)+sensitivity))
youden_index <- sensitivity + specificity - 1
pred <- prediction(predictions, labels)
auc_perf <- performance(pred, measure = "auc")
area_under_roc_curve <- auc_perf@y.values
returnFrame<- data.frame(accuracy = c(accuracy),
sensitivity = c(sensitivity),
specificity = c(specificity),
false_positive_rate = c(false_positive_rate),
false_negative_rate = c(false_negative_rate),
positive_predictive_value = c(positive_predictive_value),
negative_predictive_value = c(negative_predictive_value),
area_under_roc_curve = c(area_under_roc_curve),
positive_likelihood_ratio = c(positive_likelihood_ratio),
negative_likelihood_ratio = c(negative_likelihood_ratio),
diagnostic_odds_ratio = c(diagnostic_odds_ratio),
f1_score = c(f1_score),
f2_score = c(f2_score),
youden_index = c(youden_index))
return(returnFrame)
c(accuracy,
sensitivity,
specificity,
false_positive_rate,
false_negative_rate,
positive_predictive_value,
negative_predictive_value,
area_under_roc_curve,
positive_likelihood_ratio,
negative_likelihood_ratio,
diagnostic_odds_ratio,
f1_score,
f2_score,
youden_index)
}
hm <- calcMetrics(lasso_confusion_matrix,
lasso_predictions,
test_data$Outcome)
View(hm)
pred <- prediction(predictions, labels)
predictions <- lasso_predictions
labels <- test_data$Outcome
pred <- prediction(predictions, labels)
auc_perf <- performance(pred, measure = "auc")
area_under_roc_curve <- auc_perf@y.values
View(area_under_roc_curve)
area_under_roc_curve
area_under_roc_curve[1]
area_under_roc_curve <- auc_perf@y.values[1]
area_under_roc_curve <- auc_perf@y.values[1]
area_under_roc_curve <- auc_perf@y.values[1]
area_under_roc_curve <- auc_perf@y.values[[1]]
hm <- calcMetrics(lasso_confusion_matrix,
lasso_predictions,
test_data$Outcome)
# libraries
library(glmnet)
library(caret)
set.seed(37)
# open data
train_data <- read.csv("data/clean/training.csv")
test_data <- read.csv("data/clean/testing.csv")
# glm models require matrices
train_data_glm_matrix <- model.matrix(Outcome~.,
train_data)[,-1]
test_data_glm_matrix <- model.matrix(Outcome ~ .,
test_data)[,-1]
train_data_labels <- train_data$Outcome
# set up cv
foldid <- sample(rep(seq(5), length.out = nrow(train_data)))
# fit penalized lasso model (cv)
fit_lasso_cv <- cv.glmnet(x = train_data_glm_matrix,
y = train_data_labels,
family = "binomial",
alpha = 1,
nfolds = 5,
foldid = foldid)
# select best model
lasso_model <- glmnet(x = train_data_glm_matrix,
y = train_data_labels,
family = "binomial",
alpha = 1,
lambda = fit_lasso_cv$lambda.min)
# evaluate lasso
lasso_predictions <- predict(lasso_model,
newx = test_data_glm_matrix,
type = "response")
lasso_predictions <- ifelse(lasso_predictions > 0.5,
1,
0)
lasso_confusion_matrix <- confusionMatrix(data = factor(lasso_predictions),
reference = factor(test_data$Outcome),
positive = "1")
# save
save(lasso_model, file = "models/lasso_model.RData")
save(lasso_confusion_matrix, file = "results/lasso_confusion_matrix.RData")
# fit penalized ridge model (cv)
fit_ridge_cv <- cv.glmnet(x = train_data_glm_matrix,
y = train_data_labels,
family = "binomial",
alpha = 0,
nfolds = 5,
foldid = foldid)
# select best model
ridge_model <- glmnet(x = train_data_glm_matrix,
y = train_data_labels,
family = "binomial",
alpha = 0,
lambda = fit_ridge_cv$lambda.min)
# evaluate ridge
ridge_predictions <- predict(ridge_model,
newx = test_data_glm_matrix,
type = "response")
ridge_predictions <- ifelse(ridge_predictions > 0.5,
1,
0)
ridge_confusion_matrix <- confusionMatrix(data = factor(ridge_predictions),
reference = factor(test_data$Outcome),
positive = "1")
# save
save(ridge_model, file = "models/ridge_model.RData")
save(ridge_confusion_matrix, file = "results/ridge_confusion_matrix.RData")
# elastic net
cross_validation_control <- trainControl(method = "cv",
number = 5)
# tune model
elastic_net_model_cv <- train(factor(Outcome) ~ .,
data = train_data,
method = "glmnet",
trControl = cross_validation_control,
foldid = foldid,
family = "binomial",
tuneLength = 25)
# best model
elastic_net_model <- glmnet(x = train_data_glm_matrix,
y = train_data_labels,
lambda = elastic_net_model_cv$bestTune$lambda,
alpha = elastic_net_model_cv$bestTune$alpha)
# evaluate elastic net
elastic_net_predictions <- predict(elastic_net_model,
newx = test_data_glm_matrix,
type = "response")
elastic_net_predictions <- ifelse(elastic_net_predictions > 0.5,
1,
0)
elastic_net_confusion_matrix <- confusionMatrix(data = factor(elastic_net_predictions),
reference = factor(test_data$Outcome),
positive = "1")
# save
save(elastic_net_model, file = "models/elastic_net_model.RData")
save(elastic_net_confusion_matrix, file = "results/elastic_net_confusion_matrix.RData")
load("results/random_forest_model.RData")
setwd("C:/Users/kurti/Desktop/TumorPrediction")
load("results/random_forest_model.RData")
load("models/random_forest_model.RData")
# evaluate best model
random_forest_predictions <- predict(random_forest_model,
test_data)
# libraries
library(ranger)
set.seed(37)
# evaluate best model
random_forest_predictions <- predict(random_forest_model,
test_data)
random_forest_predictions <- random_forest_predictions$predictions
random_forest_confusion_matrix <- confusionMatrix(data = factor(random_forest_predictions),
reference = factor(test_data$Outcome),
positive = "1")
save(random_forest_confusion_matrix, file = "results/random_forest_confusion_matrix.RData")
# libraries
library(e1071)
load("models/best_linear_svm_model.RData")
linear_svm_predictions <- predict(best_linear_svm,
test_data)
linear_svm_confusion_matrix <- confusionMatrix(data = factor(linear_svm_predictions),
reference = factor(test_data$Outcome),
positive = "1")
save(linear_svm_confusion_matrix, file = "results/linear_svm_confusion_matrix.RData")
load("models/best_radial_svm_model.RData")
radial_svm_predictions <- predict(best_radial_svm,
test_data)
radial_svm_confusion_matrix <- confusionMatrix(data = factor(radial_svm_predictions),
reference = factor(test_data$Outcome),
positive = "1")
save(radial_svm_confusion_matrix, file = "results/radial_svm_confusion_matrix.RData")
load("models/best_xgb_model_full.RData")
xgb_predictions <- predict(best_xgb_model_full,
xgb_test_data)
library(xgboost)
library(caret)
set.seed(37)
# load data
train_data <- read.csv("data/clean/training.csv")
test_data <- read.csv("data/clean/testing.csv")
train_labels <- train_data$Outcome
train_data$Outcome <- NULL
xgb_train_data <- xgb.DMatrix(data.matrix(train_data), label = train_labels)
test_labels <- test_data$Outcome
test_data$Outcome <- NULL
xgb_test_data <- xgb.DMatrix(data.matrix(test_data), label = test_labels)
xgb_predictions <- predict(best_xgb_model_full,
xgb_test_data)
xgb_predictions <- ifelse(xgb_predictions > 0.5,
1,
0)
xgb_confusion_matrix <- confusionMatrix(data = factor(xgb_predictions),
reference = factor(test_labels),
positive = "1")
save(xgb_confusion_matrix, file = "results/xgb_confusion_matrix.RData")
